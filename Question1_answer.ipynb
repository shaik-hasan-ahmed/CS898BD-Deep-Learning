{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8598219a-a47e-4d8c-b420-d3d9c279b4ac",
   "metadata": {},
   "source": [
    "<h1>Question 1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b300bd4-f427-456f-bbb6-ce23e07ad4cd",
   "metadata": {},
   "source": [
    "1.Get Tiny ImageNet dataset<br>\n",
    "2 Create your own dataset from the Tiny ImageNet dataset as follows:<br>\n",
    "o Consider only 100 classes from the dataset<br>\n",
    "o From each class, take 500 images<br>\n",
    "o Split your dataset into training, testing, and validation sets such that training\n",
    "set contains 30,000, testing contains, 10,000, and validation set contains\n",
    "10,000 images<br>\n",
    "o Prepare your data for your model as described in section 2 of AlexNet paper.<br>\n",
    "o Important: You code must have appropriate comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9722902-7eeb-4349-acaa-d8bce9561e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaik\\anaconda3\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (4.3.5) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Import the required modules\n",
    "import numpy as np\n",
    "import deeplake\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2edc420-09d2-4b5d-91ec-e3676d361adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/tiny-imagenet-train\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/tiny-imagenet-train loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "#import the dataset using deeplake\n",
    "ds = deeplake.load(\"hub://activeloop/tiny-imagenet-train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b013a23e-367e-456f-8bd7-78efcd4cded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tensors: ['bbox', 'image', 'label']\n",
      "No of samples in the dataset : 100000\n"
     ]
    }
   ],
   "source": [
    "#print available tensors in the dataset\n",
    "print(\"Available tensors:\", list(ds.tensors.keys()))\n",
    "total_samples = len(ds)\n",
    "#Printing no of images in the dataset\n",
    "print(\"No of samples in the dataset :\",total_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9003b335-5ced-464c-8edc-4c053378a7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiny ImageNet has 200 classes\n"
     ]
    }
   ],
   "source": [
    "# Get no of classes in the dataset\n",
    "labels = ds.label.numpy().flatten()\n",
    "count_classes= len(np.unique(labels))\n",
    "\n",
    "print(f\"Tiny ImageNet has {count_classes} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40a6720a-8ee5-479d-aeb1-a4af739c15ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of classes selected : 100\n"
     ]
    }
   ],
   "source": [
    "#Fetch randomly 100 classes in the tinyimage dataset\n",
    "selected_classes = np.random.choice(count_classes , size =100, replace=False)\n",
    "print(f\"No of classes selected : {len(selected_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98ff56b0-3d1d-4e40-87f1-4cfb071ae08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform mapping from old label to new label (0 to 99)\n",
    "old_to_new_label = {old_label: idx for idx, old_label in enumerate(selected_classes)}\n",
    "new_to_old_label = {idx: old_label for old_label, idx in old_to_new_label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74d1af10-016f-4cea-9ba2-1b68dc4691c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each fetch 500 images randomly\n",
    "selected_indices = []\n",
    "for cls in selected_classes :\n",
    "    #All indices where label and cls are equal\n",
    "    cls_indices = np.where(labels == cls)[0]\n",
    "    #Randomly take 500 images without replacement\n",
    "    sampled = np.random.choice(cls_indices, size = 500, replace = False)\n",
    "    selected_indices.extend(sampled)\n",
    "\n",
    "#Convert to numpy array and shuffle\n",
    "selected_indices = np.array(selected_indices)\n",
    "np.random.shuffle(selected_indices) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bef886a4-b40a-40dd-8552-326abb07378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in dataset : 50000\n"
     ]
    }
   ],
   "source": [
    "#Verify the total count after shuffling\n",
    "assert len(selected_indices) == 50000\n",
    "print(f\"Total samples in dataset : {len(selected_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e987d94-2c02-4010-b1fe-ea9965371165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 30000\n",
      "Validation set size: 10000\n",
      "Test set size: 10000\n"
     ]
    }
   ],
   "source": [
    "#set indices values for each dataset\n",
    "train_index = selected_indices[:30000]\n",
    "val_index = selected_indices[30000:40000]\n",
    "test_index = selected_indices[40000:50000]\n",
    "\n",
    "#split the data using the indexes fecthed\n",
    "train_ds = ds[train_index.tolist()]\n",
    "val_ds = ds[val_index.tolist()]\n",
    "test_ds = ds[test_index.tolist()]\n",
    "\n",
    "#dataset sizes after the split\n",
    "# Confirm sizes\n",
    "print(f\"Training set size: {len(train_ds)}\")\n",
    "print(f\"Validation set size: {len(val_ds)}\")\n",
    "print(f\"Test set size: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "494dd4fe-ec1e-4614-ab5b-b32dfa775099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement Alexnet Preprocessing( computing mean RGB values of Training dataset)\n",
    "def compute_training_mean(dataset, target_size=227, batch_size=100):\n",
    "    total_sum = np.zeros(3)\n",
    "    total_pixels = 0\n",
    "\n",
    "    for i in tqdm(range(0, len(dataset), batch_size), desc=\"Computing mean\"):\n",
    "        # Load images as list (handles different image shapes)\n",
    "        image_list = dataset[i:i+batch_size].image.numpy(aslist=True)\n",
    "\n",
    "        for img in image_list:\n",
    "            # Handle different image shapes\n",
    "            if img.ndim == 2:\n",
    "                # Grayscale: (H, W)  -- >convert to (H, W, 3)\n",
    "                img = np.stack([img] * 3, axis=-1)\n",
    "            elif img.ndim == 3 and img.shape[2] == 1:\n",
    "                # Grayscale with channel dim: (H, W, 1) -- > (H, W, 3)\n",
    "                img = np.concatenate([img] * 3, axis=-1)\n",
    "            elif img.ndim == 3 and img.shape[2] == 3:\n",
    "                # if already then pass\n",
    "                pass\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected image shape: {img.shape}\")\n",
    "\n",
    "            # Ensure dtype is uint8\n",
    "            if img.dtype != np.uint8:\n",
    "                img = img.astype(np.uint8)\n",
    "\n",
    "            # Convert to PIL and resize to the target_size\n",
    "            pil_img = Image.fromarray(img, mode='RGB')\n",
    "            resized = pil_img.resize((target_size, target_size), Image.BILINEAR)\n",
    "            resized_np = np.array(resized)  # Shape: (227, 227, 3)\n",
    "\n",
    "            # Accumulate the sum over height and width \n",
    "            total_sum += resized_np.sum(axis=(0, 1))  # Sum over H, W → (3,)\n",
    "            total_pixels += resized_np.shape[0] * resized_np.shape[1]  # 227*227\n",
    "    mean_rgb = total_sum / total_pixels\n",
    "    return mean_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f9be5df-609d-4283-a9d3-8bfe9a280bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing mean: 100%|██████████| 300/300 [54:50<00:00, 10.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean (RGB): [123.56455408928306, 114.61865774935796, 100.27033949232471]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Caliculate the mean of training dataset\n",
    "train_mean_rgb = compute_training_mean(train_ds, target_size=227).tolist()\n",
    "print(f\"Training mean (RGB): {train_mean_rgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6aabbc62-757b-440a-a376-dc14a4de7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for alexnet transformer \n",
    "#Return transform that\n",
    "# - converts the numpy array to PIL\n",
    "# - resize smaller edge to target_size\n",
    "# - Center crops to target_size\n",
    "# - converts to tensor (0-1) then scales back to 0-255\n",
    "# - Subtracts per channel mean not std scaling as in original AlexNet\n",
    "def alexnet_transform(mean_rgb, target_size=227):\n",
    "    return transforms.Compose([\n",
    "        transforms.ToPILImage(), #converts numpy array (H,W,C) to PIL\n",
    "        transforms.Resize(target_size), #resize the smaller edge to 227\n",
    "        transforms.CenterCrop(target_size), #Ensure it has 227x227\n",
    "        transforms.ToTensor(), # Converts (H,W,C) and scale between 0 to 1\n",
    "        transforms.Lambda(lambda x:x *255.0), #Undo ToTensor scaling\n",
    "        transforms.Normalize(\n",
    "            mean=mean_rgb, #Subract with training mean\n",
    "            std=[1.0,1.0,1.0]  #No std scaling\n",
    "            ),\n",
    "        ])                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a78e00e7-b533-4c35-9b04-e5b00d1416b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a Custom dataset wrapper for Deeplake with alexnet processing remaps original lables to 0-99 based on selected_classes\n",
    "class AlexNetDataset(Dataset):\n",
    "    \" A PyTorch Dataset wrapper for DeepLake datasets, compatible with AlexNet preprocessing.\"\n",
    "\n",
    "    def __init__(self, ds, transform = None):\n",
    "        self.ds = ds\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sample = self.ds[idx]\n",
    "        image = sample.image.numpy()\n",
    "        label = sample.label.numpy.item() \n",
    "\n",
    "        if self.transform :\n",
    "            image = self.transform(image)\n",
    "        return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52f68cc8-ecc4-4619-bda7-02bd78d3e9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples in Training dataset : 30000\n",
      "Samples in Validation dataset : 10000\n",
      "Samples in Test dataset : 10000\n"
     ]
    }
   ],
   "source": [
    "#create transform using calculated mean on the training dataset\n",
    "train_transform = alexnet_transform(train_mean_rgb)\n",
    "val_transform = alexnet_transform(train_mean_rgb)\n",
    "test_transform = alexnet_transform(train_mean_rgb)\n",
    "\n",
    "#wrap using each datasets created\n",
    "train_dataset = AlexNetDataset(train_ds, transform=train_transform)\n",
    "val_dataset = AlexNetDataset(val_ds, transform = val_transform)\n",
    "test_dataset = AlexNetDataset(test_ds, transform = test_transform)\n",
    "\n",
    "#Verfiy the dataset sizes\n",
    "print(f\"Samples in Training dataset : {len(train_dataset)}\")\n",
    "print(f\"Samples in Validation dataset : {len(val_dataset)}\")\n",
    "print(f\"Samples in Test dataset : {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3620e29c-bad5-4139-b2c6-095c3bc1a021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
